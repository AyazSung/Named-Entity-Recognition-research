{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-27T14:31:08.270764600Z",
     "start_time": "2023-11-27T14:30:56.271031800Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SunagatullinAyaz\\.conda\\envs\\pythonProject2\\lib\\site-packages\\spacy\\util.py:910: UserWarning: [W095] Model 'en_core_web_sm' (3.6.0) was trained with spaCy v3.6.0 and may not be 100% compatible with the current version (3.7.1). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "\n",
    "spacy.prefer_gpu()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import ast\n",
    "\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from spacy.util import filter_spans\n",
    "\n",
    "from spacy.training import Example\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "df_final = pd.read_csv('dataset/df_final.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T14:31:08.439755900Z",
     "start_time": "2023-11-27T14:31:08.268756100Z"
    }
   },
   "id": "f08c3f7f7ac0cde5"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                                            Sentence  \\\n0  Thousands of demonstrators have marched throug...   \n1  Families of soldiers killed in the conflict jo...   \n2  They marched from the Houses of Parliament to ...   \n3  Police put the number of marchers at 10,000 wh...   \n4  The protest comes on the eve of the annual con...   \n\n                                                 Tag  \n0  ['O', 'O', 'O', 'O', 'O', 'O', 'B-GEO', 'O', '...  \n1  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n2  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n3  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n4  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sentence</th>\n      <th>Tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Thousands of demonstrators have marched throug...</td>\n      <td>['O', 'O', 'O', 'O', 'O', 'O', 'B-GEO', 'O', '...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Families of soldiers killed in the conflict jo...</td>\n      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>They marched from the Houses of Parliament to ...</td>\n      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Police put the number of marchers at 10,000 wh...</td>\n      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The protest comes on the eve of the annual con...</td>\n      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T14:31:08.493787200Z",
     "start_time": "2023-11-27T14:31:08.447759500Z"
    }
   },
   "id": "438d3ae2fd0bb7c7"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SunagatullinAyaz\\.conda\\envs\\pythonProject2\\lib\\site-packages\\spacy\\util.py:910: UserWarning: [W095] Model 'en_core_web_lg' (3.6.0) was trained with spaCy v3.6.0 and may not be 100% compatible with the current version (3.7.1). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\", disable=[\"tagger\", \"parser\", \"ner\", \"lemmatizer\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T14:31:53.219598700Z",
     "start_time": "2023-11-27T14:31:45.604953300Z"
    }
   },
   "id": "897072e0913885cd"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Modifying the spacy tokenizer to not split on hyphens\n",
    "\n",
    "from spacy.lang.char_classes import ALPHA, ALPHA_LOWER, ALPHA_UPPER\n",
    "from spacy.lang.char_classes import CONCAT_QUOTES, LIST_ELLIPSES, LIST_ICONS\n",
    "from spacy.util import compile_infix_regex\n",
    "\n",
    "# Modify tokenizer infix patterns\n",
    "infixes = (\n",
    "        LIST_ELLIPSES\n",
    "        + LIST_ICONS\n",
    "        + [\n",
    "            r\"(?<=[0-9])[+\\\\-\\\\*^](?=[0-9-])\",\n",
    "            r\"(?<=[{al}{q}])\\\\.(?=[{au}{q}])\".format(\n",
    "                al=ALPHA_LOWER, au=ALPHA_UPPER, q=CONCAT_QUOTES\n",
    "            ),\n",
    "            r\"(?<=[{a}]),(?=[{a}])\".format(a=ALPHA),\n",
    "            # âœ… Commented out regex that splits on hyphens between letters:\n",
    "            # r\"(?<=[{a}])(?:{h})(?=[{a}])\".format(a=ALPHA, h=HYPHENS),\n",
    "            r\"(?<=[{a}0-9])[:<>=/](?=[{a}])\".format(a=ALPHA),\n",
    "        ]\n",
    ")\n",
    "\n",
    "infix_re = compile_infix_regex(infixes)\n",
    "nlp.tokenizer.infix_finditer = infix_re.finditer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T14:31:53.443008100Z",
     "start_time": "2023-11-27T14:31:53.245603900Z"
    }
   },
   "id": "6a6614fbbb00f211"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "final_data = []\n",
    "for i in range(len(df_final)):\n",
    "    temp_dict = {}\n",
    "    temp_dict['text'] = df_final['Sentence'][i]\n",
    "    temp_dict['entities'] = []\n",
    "    doc = nlp(df_final['Sentence'][i])\n",
    "    tag = df_final['Tag'][i]\n",
    "    for token in doc:\n",
    "        m = 0\n",
    "        start = token.idx\n",
    "        end = start + len(token.text)\n",
    "        label = tag[m]\n",
    "        temp_dict['entities'].append((start, end, label))\n",
    "        m += 1\n",
    "    final_data.append(temp_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T14:34:18.798074600Z",
     "start_time": "2023-11-27T14:31:53.519799400Z"
    }
   },
   "id": "16d251da6974f661"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records:  47959\n",
      "\n",
      "Train data length:  40765\n",
      "Test data length:  7194\n"
     ]
    }
   ],
   "source": [
    "# Split data into train and test\n",
    "print(\"Number of records: \", len(final_data))\n",
    "train = final_data[:int(0.85 * len(final_data))]\n",
    "test = final_data[int(0.85 * len(final_data)):]\n",
    "\n",
    "print(\"\\nTrain data length: \", len(train))\n",
    "print(\"Test data length: \", len(test))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T14:34:18.885767700Z",
     "start_time": "2023-11-27T14:34:18.835188100Z"
    }
   },
   "id": "c8ba1f29f8597e7f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "\n",
    "def convert_data(data, output_path):\n",
    "    # create a docbin object\n",
    "    db = DocBin()\n",
    "    for example in tqdm(data):\n",
    "        text = example['text']\n",
    "        labels = example['entities']\n",
    "        # create a doc object from text\n",
    "        doc = nlp.make_doc(text)\n",
    "        ents = []\n",
    "        for start, end, label in labels:\n",
    "            span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "            if span is not None:\n",
    "                ents.append(span)\n",
    "        filtered_ents = filter_spans(ents)\n",
    "        doc.ents = filtered_ents\n",
    "        db.add(doc)\n",
    "    db.to_disk(output_path)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "320bb56a7c4bf6c2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "convert_data(train, 'output/train.spacy')\n",
    "convert_data(test, 'output/dev.spacy')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d1adc0df08c0c1b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
